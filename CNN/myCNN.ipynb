{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlJoy19u9_gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2TsbmKeeQYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiBoPA28NxS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv2D: # 卷积层\n",
        "    def __init__(self, filter_n, filter_size):\n",
        "        self.filter_n = filter_n # 滤波器/卷积核数量\n",
        "        self.filter_size = filter_size # 滤波器/卷积核大小\n",
        "        self.filters = np.random.randn(filter_n, filter_size, filter_size) / 9 # filter_n个滤波器/卷积核\n",
        "\n",
        "    def generateRegions(self, input): # 生成区块们\n",
        "        h, w = input.shape\n",
        "\n",
        "        for i in range(h-self.filter_size+1):\n",
        "            for j in range(w-self.filter_size+1):\n",
        "                region = input[i:i+self.filter_size, j:j+self.filter_size]\n",
        "                yield region, i, j\n",
        "\n",
        "    def forward(self, input): # 前向传播\n",
        "        h, w = input.shape\n",
        "        output = np.zeros((h-self.filter_size+1, w-self.filter_size+1, self.filter_n))\n",
        "\n",
        "        for region, i, j in self.generateRegions(input):\n",
        "            output[i, j] = np.sum(region * self.filters, axis = (1, 2)) \n",
        "\n",
        "        self.input = input\n",
        "        return output\n",
        "\n",
        "    def backprop(self, d_L_d_output, alpha): # 反向传播\n",
        "        d_L_d_filters = np.zeros(self.filters.shape)\n",
        "\n",
        "        for region, i, j in self.generateRegions(self.input):\n",
        "          for f in range(self.filter_n):\n",
        "            d_L_d_filters[f] += d_L_d_output[i, j, f] * region\n",
        "\n",
        "        self.filters -= alpha / (d_L_d_output.shape[0] * d_L_d_output.shape[1]) * d_L_d_filters # 更新卷积核们"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzwQIq9fc6Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaxPooling2D: # 池化层/采样层/汇聚层\n",
        "    def generateRegions(self, input): # 生成区块们\n",
        "        h, w, filter_n = input.shape\n",
        "\n",
        "        for i in range(h // 2):\n",
        "            for j in range(w // 2):\n",
        "                region = input[i*2:i*2+2, j*2:j*2+2]\n",
        "                yield region, i, j\n",
        "\n",
        "    def forward(self, input): # 前向传播\n",
        "        h, w, filter_n = input.shape\n",
        "        output = np.zeros((h//2, w//2, filter_n))\n",
        "\n",
        "        for region, i, j in self.generateRegions(input):\n",
        "            output[i, j] = np.amax(region, axis = (0, 1)) \n",
        "        \n",
        "        self.input = input\n",
        "        self.output = output\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backprop(self, d_L_d_output): # 反向传播\n",
        "      d_L_d_input = np.zeros(self.input.shape)\n",
        "\n",
        "      for region, i, j in self.generateRegions(self.input):\n",
        "        h, w, filter_n = region.shape\n",
        "        maxs = np.amax(region, axis=(0, 1)) # filter_n个2*2小区块每个中最大的那一个们\n",
        "\n",
        "        for i2 in range(h):\n",
        "          for j2 in range(w):\n",
        "            for f2 in range(filter_n):\n",
        "              if(region[i2, j2, f2] == maxs[f2]):\n",
        "                d_L_d_input[i*2+i2, j*2+j2, f2] = d_L_d_output[i, j, f2]\n",
        "\n",
        "      return d_L_d_input"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWwwzsGie16K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Softmax: # 全连接层\n",
        "  def __init__(self, input_len, class_n):\n",
        "    self.weights = np.random.randn(input_len+1, class_n) / (input_len+1) # 增广权向量\n",
        "    self.class_n = class_n # 类别数\n",
        "\n",
        "  def forward(self, input): # 前向传播\n",
        "    x = np.append(input.flatten(), 1) # 增广特征向量\n",
        "    fs = np.dot(x, self.weights) # f = wx\n",
        "    exps = np.exp(fs)\n",
        "    ps = exps / np.sum(exps, axis=0) # 属于各个类的概率\n",
        "\n",
        "    self.input = input\n",
        "    self.x = x\n",
        "    self.ps = ps\n",
        "\n",
        "    return ps\n",
        "\n",
        "  def backprop(self, label, alpha): # 反向传播\n",
        "    y = np.zeros(self.class_n)\n",
        "    y[label] = 1\n",
        "\n",
        "    d_L_d_x = - 1/self.class_n * self.weights[:-1] @ (y - self.ps) # 损失函数对输入x=input.flatten的导数\n",
        "    self.weights += alpha * np.mat(self.x).T @ np.mat(y - self.ps) # SGD更新权重\n",
        "\n",
        "    return d_L_d_x.reshape(self.input.shape)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6RMc0Ma1hVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv = Conv2D(8, 3)\n",
        "maxpool = MaxPooling2D()\n",
        "dense = Softmax(13*13*8, 10)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z867Bh94tW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(image, label): # 前向传播\n",
        "  output = conv.forward((image/255)-0.5)\n",
        "  output = maxpool.forward(output)\n",
        "  output = dense.forward(output)\n",
        "\n",
        "  loss = -np.log(output[label]) # 损失\n",
        "  acc = 1 if np.argmax(output) == label else 0 # 是否分类正确\n",
        "\n",
        "  return output, loss, acc\n",
        "\n",
        "def backprop(label, alpha): # 反向传播\n",
        "  d_L = dense.backprop(label, alpha)\n",
        "  d_L = maxpool.backprop(d_L)\n",
        "  conv.backprop(d_L, alpha)\n",
        "\n",
        "def train(image, label, alpha = .05): # 拿一个label类的image训练一次\n",
        "  out, loss, acc = forward(image, label)\n",
        "  backprop(label, alpha)\n",
        "  return loss, acc"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwaHH88Y2bGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "52dcb975-47ab-4794-ba04-538c1503e374"
      },
      "source": [
        "loss = 0\n",
        "correct_n = 0\n",
        "\n",
        "for epoch in range(3):\n",
        "  print('--- Epoch %d ---' % (epoch + 1))\n",
        "\n",
        "  for i, (im, label) in enumerate(zip(train_images[:1000], train_labels[:1000])): # 拿train_images[:1000]里的image们训练\n",
        "    if(i%100 == 99):\n",
        "      print('[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
        "        (i + 1, loss / 100, correct_n))\n",
        "      loss = 0\n",
        "      correct_n = 0\n",
        "\n",
        "    lo, acc = train(im, label) # 拿一个label类的image训练一次\n",
        "    loss += lo\n",
        "    correct_n += acc\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Epoch 1 ---\n",
            "[Step 100] Past 100 steps: Average Loss 1.892 | Accuracy: 36%\n",
            "[Step 200] Past 100 steps: Average Loss 1.264 | Accuracy: 65%\n",
            "[Step 300] Past 100 steps: Average Loss 0.956 | Accuracy: 74%\n",
            "[Step 400] Past 100 steps: Average Loss 0.720 | Accuracy: 80%\n",
            "[Step 500] Past 100 steps: Average Loss 0.744 | Accuracy: 81%\n",
            "[Step 600] Past 100 steps: Average Loss 0.843 | Accuracy: 72%\n",
            "[Step 700] Past 100 steps: Average Loss 0.755 | Accuracy: 78%\n",
            "[Step 800] Past 100 steps: Average Loss 0.548 | Accuracy: 84%\n",
            "[Step 900] Past 100 steps: Average Loss 0.665 | Accuracy: 81%\n",
            "[Step 1000] Past 100 steps: Average Loss 0.690 | Accuracy: 81%\n",
            "--- Epoch 2 ---\n",
            "[Step 100] Past 100 steps: Average Loss 0.493 | Accuracy: 86%\n",
            "[Step 200] Past 100 steps: Average Loss 0.477 | Accuracy: 85%\n",
            "[Step 300] Past 100 steps: Average Loss 0.484 | Accuracy: 86%\n",
            "[Step 400] Past 100 steps: Average Loss 0.289 | Accuracy: 92%\n",
            "[Step 500] Past 100 steps: Average Loss 0.464 | Accuracy: 85%\n",
            "[Step 600] Past 100 steps: Average Loss 0.499 | Accuracy: 82%\n",
            "[Step 700] Past 100 steps: Average Loss 0.501 | Accuracy: 86%\n",
            "[Step 800] Past 100 steps: Average Loss 0.357 | Accuracy: 93%\n",
            "[Step 900] Past 100 steps: Average Loss 0.540 | Accuracy: 82%\n",
            "[Step 1000] Past 100 steps: Average Loss 0.506 | Accuracy: 87%\n",
            "--- Epoch 3 ---\n",
            "[Step 100] Past 100 steps: Average Loss 0.379 | Accuracy: 87%\n",
            "[Step 200] Past 100 steps: Average Loss 0.370 | Accuracy: 91%\n",
            "[Step 300] Past 100 steps: Average Loss 0.405 | Accuracy: 89%\n",
            "[Step 400] Past 100 steps: Average Loss 0.212 | Accuracy: 96%\n",
            "[Step 500] Past 100 steps: Average Loss 0.384 | Accuracy: 88%\n",
            "[Step 600] Past 100 steps: Average Loss 0.370 | Accuracy: 90%\n",
            "[Step 700] Past 100 steps: Average Loss 0.410 | Accuracy: 88%\n",
            "[Step 800] Past 100 steps: Average Loss 0.291 | Accuracy: 95%\n",
            "[Step 900] Past 100 steps: Average Loss 0.476 | Accuracy: 84%\n",
            "[Step 1000] Past 100 steps: Average Loss 0.416 | Accuracy: 91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iuv8L1Wl0P2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0ed31a65-8d2b-4ac6-fa62-6ca75aa138e4"
      },
      "source": [
        "# Test the CNN\n",
        "print('\\n--- Testing the CNN ---')\n",
        "loss = 0\n",
        "num_correct = 0\n",
        "for im, label in zip(test_images, test_labels):\n",
        "  _, l, acc = forward(im, label)\n",
        "  loss += l\n",
        "  num_correct += acc\n",
        "\n",
        "num_tests = len(test_images)\n",
        "print('Test Loss:', loss / num_tests)\n",
        "print('Test Accuracy:', num_correct / num_tests)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--- Testing the CNN ---\n",
            "Test Loss: 0.5040411338286891\n",
            "Test Accuracy: 0.8364\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}